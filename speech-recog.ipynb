{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Steps added:\n**Exploratory Data Analysis (EDA):**\n\nWaveform Plot: Shows the raw audio waveform.\nSpectrogram: Visualizes frequencies over time in dB scale.\nZero-crossing rate: How often the signal changes from positive to negative.\nRoot Mean Square Energy (RMSE): Measures the amplitude (energy) in the signal.\n**Feature Extraction:**\n\nMFCC (Mel Frequency Cepstral Coefficients): Essential feature for audio classification.\nChroma feature: Used to represent 12 different pitch classes.\nSpectral Contrast: Measures the difference between peaks and valleys in a spectrum.\n**Data Augmentation:**\n\nAdding Noise: Introduces random noise to simulate different environments.\nTime Stretching: Stretches the audio, changing the speed without altering pitch.\nPitch Shifting: Changes the pitch of the audio without affecting speed.\nTime Shifting: Shifts the audio data to the right/left to simulate offset recordings.","metadata":{}},{"cell_type":"code","source":"# System libraries\nimport os\nfrom IPython.display import Markdown, Audio, display\n\n# Data manipulation and visualization libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Audio processing libraries\nimport librosa\nimport librosa.display\n\n# Play Audio sample\naudio_file_name = \"data/kids_are_talking_by_the_door.wav\"\nAudio(audio_file_name)\n\n# Load the audio file\ndata, sample_rate = librosa.load(audio_file_name)\nprint(f'Sample rate: {sample_rate}')\nprint(f'Audio data type: {type(data)}')\nprint(f'Audio data shape: {data.shape}')\n\n# Convert audio to DataFrame\ndf = pd.DataFrame(data)\n\n# Describe the audio data\nprint(df.describe())\n\n# Plot the waveform of the audio data\nplt.figure(figsize=(10, 5))\nplt.plot(data, lw=1)\nplt.title('Kids are talking by the door - Audio waveform')\nplt.xlabel('Sample index')\nplt.ylabel('Amplitude')\nplt.show()\n\n# Trim silence from the audio file\ndata_trimmed, _ = librosa.effects.trim(data, top_db=20)\n\n# Convert trimmed audio to DataFrame\ndf_trimmed = pd.DataFrame(data_trimmed)\n\n# Describe the trimmed audio data\nprint(df_trimmed.describe())\n\n# Plot the trimmed audio waveform\nplt.figure(figsize=(10, 5))\nplt.plot(data_trimmed, lw=1)\nplt.title('Kids are talking by the door - Trimmed audio waveform')\nplt.xlabel('Sample index')\nplt.ylabel('Amplitude')\nplt.show()\n\n### Additional EDA ###\n\n# Plot the Spectrogram\nplt.figure(figsize=(10, 5))\nD = librosa.amplitude_to_db(np.abs(librosa.stft(data)), ref=np.max)\nlibrosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log')\nplt.colorbar(format='%+2.0f dB')\nplt.title('Spectrogram (Log scale)')\nplt.show()\n\n# Zero-crossing rate\nzero_crossings = librosa.zero_crossings(data, pad=False)\nprint(f'Zero-crossing rate: {sum(zero_crossings)}')\n\n# Plot the zero-crossing rate over time\nzcr = librosa.feature.zero_crossing_rate(data)\nplt.figure(figsize=(10, 5))\nplt.plot(zcr[0])\nplt.title('Zero Crossing Rate')\nplt.xlabel('Frames')\nplt.ylabel('Rate')\nplt.show()\n\n# Root Mean Square Energy (RMSE)\nrms = librosa.feature.rms(data)\nplt.figure(figsize=(10, 5))\nplt.plot(rms[0])\nplt.title('Root Mean Square Energy (RMSE)')\nplt.xlabel('Frames')\nplt.ylabel('Energy')\nplt.show()\n\n### Feature Extraction ###\n\n# Mel Frequency Cepstral Coefficients (MFCC)\nmfccs = librosa.feature.mfcc(data, sr=sample_rate, n_mfcc=13)\nplt.figure(figsize=(10, 5))\nlibrosa.display.specshow(mfccs, sr=sample_rate, x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.show()\n\n# Chroma Feature\nchroma_stft = librosa.feature.chroma_stft(data, sr=sample_rate)\nplt.figure(figsize=(10, 5))\nlibrosa.display.specshow(chroma_stft, sr=sample_rate, x_axis='time', y_axis='chroma')\nplt.colorbar()\nplt.title('Chroma Feature')\nplt.show()\n\n# Spectral Contrast\nspectral_contrast = librosa.feature.spectral_contrast(data, sr=sample_rate)\nplt.figure(figsize=(10, 5))\nlibrosa.display.specshow(spectral_contrast, sr=sample_rate, x_axis='time')\nplt.colorbar()\nplt.title('Spectral Contrast')\nplt.show()\n\n### Data Augmentation ###\n\n# 1. Adding noise\nnoise = np.random.randn(len(data))\ndata_noisy = data + 0.005 * noise\n\n# Plot noisy data\nplt.figure(figsize=(10, 5))\nplt.plot(data_noisy)\nplt.title('Noisy Audio')\nplt.show()\n\n# 2. Time Stretching\ndata_stretch = librosa.effects.time_stretch(data, rate=1.2)\n\n# Plot time-stretched data\nplt.figure(figsize=(10, 5))\nplt.plot(data_stretch)\nplt.title('Time-Stretched Audio (Rate = 1.2)')\nplt.show()\n\n# 3. Pitch Shifting\ndata_pitch_shifted = librosa.effects.pitch_shift(data, sr=sample_rate, n_steps=2)\n\n# Plot pitch-shifted data\nplt.figure(figsize=(10, 5))\nplt.plot(data_pitch_shifted)\nplt.title('Pitch Shifted Audio (2 semitones up)')\nplt.show()\n\n# 4. Time Shifting\nshifted_data = np.roll(data, int(sample_rate / 10))\n\n# Plot time-shifted data\nplt.figure(figsize=(10, 5))\nplt.plot(shifted_data)\nplt.title('Time Shifted Audio')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}